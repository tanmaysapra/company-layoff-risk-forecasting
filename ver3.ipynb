{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecf1f34-d71d-4eae-87c4-9ed48b6aebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6782602f-2341-45a9-ac22-fbeb0dfde7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>industry</th>\n",
       "      <th>stage</th>\n",
       "      <th>country</th>\n",
       "      <th>event_type</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_vc_backed</th>\n",
       "      <th>is_profitable</th>\n",
       "      <th>...</th>\n",
       "      <th>macroeconomic_flag</th>\n",
       "      <th>industry_downturn_flag</th>\n",
       "      <th>geopolitical_flag</th>\n",
       "      <th>regulatory_pressure_flag</th>\n",
       "      <th>total_workforce_est</th>\n",
       "      <th>final_count</th>\n",
       "      <th>final_percentage</th>\n",
       "      <th>funds_raised</th>\n",
       "      <th>quater</th>\n",
       "      <th>reason_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [key, company, date, industry, stage, country, event_type, quarter, is_vc_backed, is_profitable, is_ai_pivot, business_model, forward_looking_flag, backward_looking_flag, timing_unclear_flag, imminent_layoff_flag, long_horizon_flag, uncertainty_flag, confirmed_flag, acquisition_flag, private_equity_flag, post_acquisition_layoff_flag, restructuring_flag, cost_cutting_flag, strategy_shift_flag, automation_ai_flag, product_exit_flag, market_exit_flag, revenue_decline_flag, profitability_pressure_flag, runway_issue_flag, offshoring_flag, management_change_flag, employee_unrest_flag, attrition_flag, repeat_layoff_flag, department_specific_flag, senior_role_impact_flag, junior_role_impact_flag, macroeconomic_flag, industry_downturn_flag, geopolitical_flag, regulatory_pressure_flag, total_workforce_est, final_count, final_percentage, funds_raised, quater, reason_category]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('before_ts.csv')\n",
    "df['date'] = pd.to_datetime(df['date']).dt.to_period('M').dt.to_timestamp()\n",
    "df = df.drop_duplicates(subset=['company', 'date'])\n",
    "df[df.duplicated(['company', 'date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8946d36-0c28-48d0-87b9-60d800ee8117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>industry</th>\n",
       "      <th>stage</th>\n",
       "      <th>country</th>\n",
       "      <th>event_type</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_vc_backed</th>\n",
       "      <th>is_profitable</th>\n",
       "      <th>...</th>\n",
       "      <th>macroeconomic_flag</th>\n",
       "      <th>industry_downturn_flag</th>\n",
       "      <th>geopolitical_flag</th>\n",
       "      <th>regulatory_pressure_flag</th>\n",
       "      <th>total_workforce_est</th>\n",
       "      <th>final_count</th>\n",
       "      <th>final_percentage</th>\n",
       "      <th>funds_raised</th>\n",
       "      <th>quater</th>\n",
       "      <th>reason_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Paid2023/01/27</td>\n",
       "      <td>#Paid</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Layoff</td>\n",
       "      <td>Q1-2023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>3.044523</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Economic Conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp;Open2022/11/17</td>\n",
       "      <td>&amp;Open</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series A</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Layoff</td>\n",
       "      <td>Q4-2022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>Q4</td>\n",
       "      <td>Cost Cutting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100 Thieves2022/07/13</td>\n",
       "      <td>100 Thieves</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>Series C</td>\n",
       "      <td>United States</td>\n",
       "      <td>Layoff</td>\n",
       "      <td>Q3-2022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Restructuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100 Thieves2023/01/10</td>\n",
       "      <td>100 Thieves</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Series C</td>\n",
       "      <td>United States</td>\n",
       "      <td>Layoff</td>\n",
       "      <td>Q1-2023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Financial Distress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10X Genomics2022/08/04</td>\n",
       "      <td>10X Genomics</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Post-IPO</td>\n",
       "      <td>United States</td>\n",
       "      <td>Layoff</td>\n",
       "      <td>Q3-2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Economic Conditions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      key       company       date    industry     stage  \\\n",
       "0         #Paid2023/01/27         #Paid 2023-01-01   Marketing  Series B   \n",
       "1         &Open2022/11/17         &Open 2022-11-01   Marketing  Series A   \n",
       "2   100 Thieves2022/07/13   100 Thieves 2022-07-01    Consumer  Series C   \n",
       "3   100 Thieves2023/01/10   100 Thieves 2023-01-01      Retail  Series C   \n",
       "4  10X Genomics2022/08/04  10X Genomics 2022-08-01  Healthcare  Post-IPO   \n",
       "\n",
       "         country event_type  quarter  is_vc_backed  is_profitable  ...  \\\n",
       "0         Canada     Layoff  Q1-2023           1.0            0.0  ...   \n",
       "1        Ireland     Layoff  Q4-2022           1.0            0.0  ...   \n",
       "2  United States     Layoff  Q3-2022           1.0            0.0  ...   \n",
       "3  United States     Layoff  Q1-2023           1.0            0.0  ...   \n",
       "4  United States     Layoff  Q3-2022           0.0            0.0  ...   \n",
       "\n",
       "   macroeconomic_flag industry_downturn_flag  geopolitical_flag  \\\n",
       "0                 1.0                    0.0                0.0   \n",
       "1                 0.0                    0.0                0.0   \n",
       "2                 0.0                    0.0                0.0   \n",
       "3                 0.0                    1.0                0.0   \n",
       "4                 1.0                    0.0                0.0   \n",
       "\n",
       "   regulatory_pressure_flag  total_workforce_est  final_count  \\\n",
       "0                       0.0                  NaN         19.0   \n",
       "1                       0.0                  NaN          9.0   \n",
       "2                       0.0                  NaN         13.5   \n",
       "3                       0.0                200.0         15.0   \n",
       "4                       0.0               1250.0        100.0   \n",
       "\n",
       "   final_percentage  funds_raised  quater      reason_category  \n",
       "0             0.170      3.044523      Q1  Economic Conditions  \n",
       "1             0.090      3.555348      Q4         Cost Cutting  \n",
       "2             0.000      4.787492      Q3        Restructuring  \n",
       "3             0.075      4.787492      Q1   Financial Distress  \n",
       "4             0.080      5.488938      Q3  Economic Conditions  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858a483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4192 entries, 0 to 4231\n",
      "Data columns (total 49 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   key                           4192 non-null   object        \n",
      " 1   company                       4192 non-null   object        \n",
      " 2   date                          4192 non-null   datetime64[ns]\n",
      " 3   industry                      4190 non-null   object        \n",
      " 4   stage                         4187 non-null   object        \n",
      " 5   country                       4190 non-null   object        \n",
      " 6   event_type                    4113 non-null   object        \n",
      " 7   quarter                       4113 non-null   object        \n",
      " 8   is_vc_backed                  4106 non-null   float64       \n",
      " 9   is_profitable                 4050 non-null   float64       \n",
      " 10  is_ai_pivot                   4113 non-null   float64       \n",
      " 11  business_model                4107 non-null   object        \n",
      " 12  forward_looking_flag          4113 non-null   float64       \n",
      " 13  backward_looking_flag         4113 non-null   float64       \n",
      " 14  timing_unclear_flag           4113 non-null   float64       \n",
      " 15  imminent_layoff_flag          4113 non-null   float64       \n",
      " 16  long_horizon_flag             4113 non-null   float64       \n",
      " 17  uncertainty_flag              4113 non-null   float64       \n",
      " 18  confirmed_flag                4113 non-null   float64       \n",
      " 19  acquisition_flag              4113 non-null   float64       \n",
      " 20  private_equity_flag           4113 non-null   float64       \n",
      " 21  post_acquisition_layoff_flag  4113 non-null   float64       \n",
      " 22  restructuring_flag            4113 non-null   float64       \n",
      " 23  cost_cutting_flag             4113 non-null   float64       \n",
      " 24  strategy_shift_flag           4113 non-null   float64       \n",
      " 25  automation_ai_flag            4113 non-null   float64       \n",
      " 26  product_exit_flag             4113 non-null   float64       \n",
      " 27  market_exit_flag              4113 non-null   float64       \n",
      " 28  revenue_decline_flag          4113 non-null   float64       \n",
      " 29  profitability_pressure_flag   4113 non-null   float64       \n",
      " 30  runway_issue_flag             4113 non-null   float64       \n",
      " 31  offshoring_flag               4113 non-null   float64       \n",
      " 32  management_change_flag        4113 non-null   float64       \n",
      " 33  employee_unrest_flag          4113 non-null   float64       \n",
      " 34  attrition_flag                4113 non-null   float64       \n",
      " 35  repeat_layoff_flag            4113 non-null   float64       \n",
      " 36  department_specific_flag      4113 non-null   float64       \n",
      " 37  senior_role_impact_flag       4113 non-null   float64       \n",
      " 38  junior_role_impact_flag       4113 non-null   float64       \n",
      " 39  macroeconomic_flag            4113 non-null   float64       \n",
      " 40  industry_downturn_flag        4113 non-null   float64       \n",
      " 41  geopolitical_flag             4113 non-null   float64       \n",
      " 42  regulatory_pressure_flag      4109 non-null   float64       \n",
      " 43  total_workforce_est           2463 non-null   float64       \n",
      " 44  final_count                   4192 non-null   float64       \n",
      " 45  final_percentage              4192 non-null   float64       \n",
      " 46  funds_raised                  4192 non-null   float64       \n",
      " 47  quater                        4113 non-null   object        \n",
      " 48  reason_category               4192 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(38), object(10)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5661ec-1bb2-4e8e-a800-d5f9ea276ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = df['company'].unique()\n",
    "\n",
    "full_dates = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='MS')\n",
    "\n",
    "full_index = pd.MultiIndex.from_product([companies, full_dates], names=['company', 'date'])\n",
    "\n",
    "full_index_df = (full_index.to_frame(index=False).rename(columns={0: 'company', 1: 'date'}))\n",
    "full_index_df['date'] = pd.to_datetime(full_index_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4430f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01',\n",
       "               '2020-07-01', '2020-08-01', '2020-09-01', '2020-10-01',\n",
       "               '2020-11-01', '2020-12-01', '2021-01-01', '2021-02-01',\n",
       "               '2021-03-01', '2021-04-01', '2021-05-01', '2021-06-01',\n",
       "               '2021-07-01', '2021-08-01', '2021-09-01', '2021-10-01',\n",
       "               '2021-11-01', '2021-12-01', '2022-01-01', '2022-02-01',\n",
       "               '2022-03-01', '2022-04-01', '2022-05-01', '2022-06-01',\n",
       "               '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01',\n",
       "               '2022-11-01', '2022-12-01', '2023-01-01', '2023-02-01',\n",
       "               '2023-03-01', '2023-04-01', '2023-05-01', '2023-06-01',\n",
       "               '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',\n",
       "               '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01',\n",
       "               '2024-03-01', '2024-04-01', '2024-05-01', '2024-06-01',\n",
       "               '2024-07-01', '2024-08-01', '2024-09-01', '2024-10-01',\n",
       "               '2024-11-01', '2024-12-01', '2025-01-01', '2025-02-01',\n",
       "               '2025-03-01', '2025-04-01', '2025-05-01', '2025-06-01',\n",
       "               '2025-07-01', '2025-08-01', '2025-09-01', '2025-10-01',\n",
       "               '2025-11-01', '2025-12-01'],\n",
       "              dtype='datetime64[ns]', freq='MS')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c59cfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)*len(full_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58729a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05619c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199500 entries, 0 to 199499\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype         \n",
      "---  ------   --------------   -----         \n",
      " 0   company  199500 non-null  object        \n",
      " 1   date     199500 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "full_index_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0464d7d-a9c1-4a9a-adf6-6147c02d5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_static_cols = [\n",
    "    'industry', 'stage', 'country', 'is_vc_backed', 'is_profitable', 'is_ai_pivot', 'business_model', 'total_workforce_est', 'funds_raised']\n",
    "\n",
    "\n",
    "event_flag_cols = [ \n",
    "    # temporal / narrative orientation \n",
    "    'forward_looking_flag', 'backward_looking_flag', 'timing_unclear_flag', 'imminent_layoff_flag', 'long_horizon_flag', \n",
    "    'uncertainty_flag', 'confirmed_flag',\n",
    "    # corporate actions \n",
    "    'acquisition_flag', 'private_equity_flag', 'post_acquisition_layoff_flag', 'restructuring_flag', 'cost_cutting_flag', 'strategy_shift_flag',\n",
    "    # operational / strategic causes \n",
    "    'automation_ai_flag', 'product_exit_flag', 'market_exit_flag', 'offshoring_flag', 'management_change_flag',\n",
    "    # workforce dynamics \n",
    "    'employee_unrest_flag', 'attrition_flag', 'repeat_layoff_flag', 'department_specific_flag', 'senior_role_impact_flag', 'junior_role_impact_flag',\n",
    "    # financial stress \n",
    "    'revenue_decline_flag', 'profitability_pressure_flag', 'runway_issue_flag',\n",
    "    # macro / external \n",
    "    'macroeconomic_flag', 'industry_downturn_flag', 'geopolitical_flag', 'regulatory_pressure_flag'\n",
    "]\n",
    "\n",
    "event_numeric_cols = ['final_count', 'final_percentage']\n",
    "\n",
    "event_metadata_cols = ['event_type', 'quater', 'reason_category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9b23ff-35ba-440e-9613-459d04c4803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_snapshot = (\n",
    "    df\n",
    "    .sort_values('date')\n",
    "    .groupby('company', as_index=False)\n",
    "    [company_static_cols]\n",
    "    .last()\n",
    ")\n",
    "\n",
    "base_df = full_index_df.copy()\n",
    "\n",
    "base_df = base_df.merge(\n",
    "    company_snapshot,\n",
    "    on='company',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4349db48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>industry</th>\n",
       "      <th>stage</th>\n",
       "      <th>country</th>\n",
       "      <th>is_vc_backed</th>\n",
       "      <th>is_profitable</th>\n",
       "      <th>is_ai_pivot</th>\n",
       "      <th>business_model</th>\n",
       "      <th>total_workforce_est</th>\n",
       "      <th>funds_raised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199495</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>10.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199496</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>10.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199497</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>10.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199498</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>10.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199499</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>10.030120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       company       date   industry     stage        country  is_vc_backed  \\\n",
       "0        #Paid 2020-03-01  Marketing  Series B         Canada           1.0   \n",
       "1        #Paid 2020-04-01  Marketing  Series B         Canada           1.0   \n",
       "2        #Paid 2020-05-01  Marketing  Series B         Canada           1.0   \n",
       "3        #Paid 2020-06-01  Marketing  Series B         Canada           1.0   \n",
       "4        #Paid 2020-07-01  Marketing  Series B         Canada           1.0   \n",
       "...        ...        ...        ...       ...            ...           ...   \n",
       "199495     xAI 2025-08-01         AI   Unknown  United States           1.0   \n",
       "199496     xAI 2025-09-01         AI   Unknown  United States           1.0   \n",
       "199497     xAI 2025-10-01         AI   Unknown  United States           1.0   \n",
       "199498     xAI 2025-11-01         AI   Unknown  United States           1.0   \n",
       "199499     xAI 2025-12-01         AI   Unknown  United States           1.0   \n",
       "\n",
       "        is_profitable  is_ai_pivot business_model  total_workforce_est  \\\n",
       "0                 0.0          0.0            B2B                  NaN   \n",
       "1                 0.0          0.0            B2B                  NaN   \n",
       "2                 0.0          0.0            B2B                  NaN   \n",
       "3                 0.0          0.0            B2B                  NaN   \n",
       "4                 0.0          0.0            B2B                  NaN   \n",
       "...               ...          ...            ...                  ...   \n",
       "199495            0.0          1.0            B2B               1500.0   \n",
       "199496            0.0          1.0            B2B               1500.0   \n",
       "199497            0.0          1.0            B2B               1500.0   \n",
       "199498            0.0          1.0            B2B               1500.0   \n",
       "199499            0.0          1.0            B2B               1500.0   \n",
       "\n",
       "        funds_raised  \n",
       "0           3.044523  \n",
       "1           3.044523  \n",
       "2           3.044523  \n",
       "3           3.044523  \n",
       "4           3.044523  \n",
       "...              ...  \n",
       "199495     10.030120  \n",
       "199496     10.030120  \n",
       "199497     10.030120  \n",
       "199498     10.030120  \n",
       "199499     10.030120  \n",
       "\n",
       "[199500 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc25dfb-01d5-4979-8df1-60142228a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_cols = (['company', 'date'] + event_flag_cols + event_numeric_cols + event_metadata_cols)\n",
    "\n",
    "event_df = df[event_cols]\n",
    "\n",
    "base_df = base_df.merge(event_df, on=['company', 'date'], how='left')\n",
    "#base_df[event_flag_cols] = base_df[event_flag_cols].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02cfaa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199500 entries, 0 to 199499\n",
      "Data columns (total 47 columns):\n",
      " #   Column                        Non-Null Count   Dtype         \n",
      "---  ------                        --------------   -----         \n",
      " 0   company                       199500 non-null  object        \n",
      " 1   date                          199500 non-null  datetime64[ns]\n",
      " 2   industry                      199360 non-null  object        \n",
      " 3   stage                         199220 non-null  object        \n",
      " 4   country                       199360 non-null  object        \n",
      " 5   is_vc_backed                  195090 non-null  float64       \n",
      " 6   is_profitable                 192290 non-null  float64       \n",
      " 7   is_ai_pivot                   195510 non-null  float64       \n",
      " 8   business_model                195160 non-null  object        \n",
      " 9   total_workforce_est           122990 non-null  float64       \n",
      " 10  funds_raised                  199500 non-null  float64       \n",
      " 11  forward_looking_flag          4113 non-null    float64       \n",
      " 12  backward_looking_flag         4113 non-null    float64       \n",
      " 13  timing_unclear_flag           4113 non-null    float64       \n",
      " 14  imminent_layoff_flag          4113 non-null    float64       \n",
      " 15  long_horizon_flag             4113 non-null    float64       \n",
      " 16  uncertainty_flag              4113 non-null    float64       \n",
      " 17  confirmed_flag                4113 non-null    float64       \n",
      " 18  acquisition_flag              4113 non-null    float64       \n",
      " 19  private_equity_flag           4113 non-null    float64       \n",
      " 20  post_acquisition_layoff_flag  4113 non-null    float64       \n",
      " 21  restructuring_flag            4113 non-null    float64       \n",
      " 22  cost_cutting_flag             4113 non-null    float64       \n",
      " 23  strategy_shift_flag           4113 non-null    float64       \n",
      " 24  automation_ai_flag            4113 non-null    float64       \n",
      " 25  product_exit_flag             4113 non-null    float64       \n",
      " 26  market_exit_flag              4113 non-null    float64       \n",
      " 27  offshoring_flag               4113 non-null    float64       \n",
      " 28  management_change_flag        4113 non-null    float64       \n",
      " 29  employee_unrest_flag          4113 non-null    float64       \n",
      " 30  attrition_flag                4113 non-null    float64       \n",
      " 31  repeat_layoff_flag            4113 non-null    float64       \n",
      " 32  department_specific_flag      4113 non-null    float64       \n",
      " 33  senior_role_impact_flag       4113 non-null    float64       \n",
      " 34  junior_role_impact_flag       4113 non-null    float64       \n",
      " 35  revenue_decline_flag          4113 non-null    float64       \n",
      " 36  profitability_pressure_flag   4113 non-null    float64       \n",
      " 37  runway_issue_flag             4113 non-null    float64       \n",
      " 38  macroeconomic_flag            4113 non-null    float64       \n",
      " 39  industry_downturn_flag        4113 non-null    float64       \n",
      " 40  geopolitical_flag             4113 non-null    float64       \n",
      " 41  regulatory_pressure_flag      4109 non-null    float64       \n",
      " 42  final_count                   4192 non-null    float64       \n",
      " 43  final_percentage              4192 non-null    float64       \n",
      " 44  event_type                    4113 non-null    object        \n",
      " 45  quater                        4113 non-null    object        \n",
      " 46  reason_category               4192 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(38), object(8)\n",
      "memory usage: 71.5+ MB\n"
     ]
    }
   ],
   "source": [
    "base_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48f140c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>industry</th>\n",
       "      <th>stage</th>\n",
       "      <th>country</th>\n",
       "      <th>is_vc_backed</th>\n",
       "      <th>is_profitable</th>\n",
       "      <th>is_ai_pivot</th>\n",
       "      <th>business_model</th>\n",
       "      <th>total_workforce_est</th>\n",
       "      <th>...</th>\n",
       "      <th>runway_issue_flag</th>\n",
       "      <th>macroeconomic_flag</th>\n",
       "      <th>industry_downturn_flag</th>\n",
       "      <th>geopolitical_flag</th>\n",
       "      <th>regulatory_pressure_flag</th>\n",
       "      <th>final_count</th>\n",
       "      <th>final_percentage</th>\n",
       "      <th>event_type</th>\n",
       "      <th>quater</th>\n",
       "      <th>reason_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Series B</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199495</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199496</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.165</td>\n",
       "      <td>Layoff</td>\n",
       "      <td>Q3</td>\n",
       "      <td>AI Pivot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199497</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199498</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199499</th>\n",
       "      <td>xAI</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>AI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199500 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       company       date   industry     stage        country  is_vc_backed  \\\n",
       "0        #Paid 2020-03-01  Marketing  Series B         Canada           1.0   \n",
       "1        #Paid 2020-04-01  Marketing  Series B         Canada           1.0   \n",
       "2        #Paid 2020-05-01  Marketing  Series B         Canada           1.0   \n",
       "3        #Paid 2020-06-01  Marketing  Series B         Canada           1.0   \n",
       "4        #Paid 2020-07-01  Marketing  Series B         Canada           1.0   \n",
       "...        ...        ...        ...       ...            ...           ...   \n",
       "199495     xAI 2025-08-01         AI   Unknown  United States           1.0   \n",
       "199496     xAI 2025-09-01         AI   Unknown  United States           1.0   \n",
       "199497     xAI 2025-10-01         AI   Unknown  United States           1.0   \n",
       "199498     xAI 2025-11-01         AI   Unknown  United States           1.0   \n",
       "199499     xAI 2025-12-01         AI   Unknown  United States           1.0   \n",
       "\n",
       "        is_profitable  is_ai_pivot business_model  total_workforce_est  ...  \\\n",
       "0                 0.0          0.0            B2B                  NaN  ...   \n",
       "1                 0.0          0.0            B2B                  NaN  ...   \n",
       "2                 0.0          0.0            B2B                  NaN  ...   \n",
       "3                 0.0          0.0            B2B                  NaN  ...   \n",
       "4                 0.0          0.0            B2B                  NaN  ...   \n",
       "...               ...          ...            ...                  ...  ...   \n",
       "199495            0.0          1.0            B2B               1500.0  ...   \n",
       "199496            0.0          1.0            B2B               1500.0  ...   \n",
       "199497            0.0          1.0            B2B               1500.0  ...   \n",
       "199498            0.0          1.0            B2B               1500.0  ...   \n",
       "199499            0.0          1.0            B2B               1500.0  ...   \n",
       "\n",
       "        runway_issue_flag  macroeconomic_flag  industry_downturn_flag  \\\n",
       "0                     NaN                 NaN                     NaN   \n",
       "1                     NaN                 NaN                     NaN   \n",
       "2                     NaN                 NaN                     NaN   \n",
       "3                     NaN                 NaN                     NaN   \n",
       "4                     NaN                 NaN                     NaN   \n",
       "...                   ...                 ...                     ...   \n",
       "199495                NaN                 NaN                     NaN   \n",
       "199496                0.0                 0.0                     0.0   \n",
       "199497                NaN                 NaN                     NaN   \n",
       "199498                NaN                 NaN                     NaN   \n",
       "199499                NaN                 NaN                     NaN   \n",
       "\n",
       "        geopolitical_flag  regulatory_pressure_flag  final_count  \\\n",
       "0                     NaN                       NaN          NaN   \n",
       "1                     NaN                       NaN          NaN   \n",
       "2                     NaN                       NaN          NaN   \n",
       "3                     NaN                       NaN          NaN   \n",
       "4                     NaN                       NaN          NaN   \n",
       "...                   ...                       ...          ...   \n",
       "199495                NaN                       NaN          NaN   \n",
       "199496                0.0                       0.0        500.0   \n",
       "199497                NaN                       NaN          NaN   \n",
       "199498                NaN                       NaN          NaN   \n",
       "199499                NaN                       NaN          NaN   \n",
       "\n",
       "        final_percentage  event_type  quater  reason_category  \n",
       "0                    NaN         NaN     NaN              NaN  \n",
       "1                    NaN         NaN     NaN              NaN  \n",
       "2                    NaN         NaN     NaN              NaN  \n",
       "3                    NaN         NaN     NaN              NaN  \n",
       "4                    NaN         NaN     NaN              NaN  \n",
       "...                  ...         ...     ...              ...  \n",
       "199495               NaN         NaN     NaN              NaN  \n",
       "199496             0.165      Layoff      Q3         AI Pivot  \n",
       "199497               NaN         NaN     NaN              NaN  \n",
       "199498               NaN         NaN     NaN              NaN  \n",
       "199499               NaN         NaN     NaN              NaN  \n",
       "\n",
       "[199500 rows x 47 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71b0a05f-4264-4bcd-99bd-9d775f364f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127499"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(base_df), len(full_index))\n",
    "# should match full_index row count\n",
    "assert len(base_df) == len(full_index)\n",
    "\n",
    "# flags should be sparse\n",
    "base_df[event_flag_cols].count().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eed4494-c01c-4cdd-80a1-d0e452ebf739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Count: 0\n",
      "       signal_forward_looking  signal_backward_looking  signal_timing_unclear  \\\n",
      "count           199500.000000             1.995000e+05          199500.000000   \n",
      "mean                 0.004033             1.978140e-02               0.000631   \n",
      "std                  0.033797             8.343483e-02               0.019245   \n",
      "min                  0.000000             0.000000e+00               0.000000   \n",
      "25%                  0.000000             0.000000e+00               0.000000   \n",
      "50%                  0.000000             5.921189e-17               0.000000   \n",
      "75%                  0.000000             8.138021e-06               0.000000   \n",
      "max                  1.000000             1.000000e+00               1.000000   \n",
      "\n",
      "       signal_imminent_layoff  signal_long_horizon  signal_uncertainty  \\\n",
      "count           199500.000000        199500.000000       199500.000000   \n",
      "mean                 0.000963             0.002311            0.000818   \n",
      "std                  0.022338             0.027481            0.019726   \n",
      "min                  0.000000             0.000000            0.000000   \n",
      "25%                  0.000000             0.000000            0.000000   \n",
      "50%                  0.000000             0.000000            0.000000   \n",
      "75%                  0.000000             0.000000            0.000000   \n",
      "max                  1.000000             1.000000            1.000000   \n",
      "\n",
      "       signal_confirmed  signal_acquisition  signal_private_equity  \\\n",
      "count      1.995000e+05       199500.000000          199500.000000   \n",
      "mean       2.166018e-02            0.004764               0.003587   \n",
      "std        8.723649e-02            0.036062               0.031928   \n",
      "min        0.000000e+00            0.000000               0.000000   \n",
      "25%        0.000000e+00            0.000000               0.000000   \n",
      "50%        4.850638e-13            0.000000               0.000000   \n",
      "75%        3.255208e-05            0.000000               0.000000   \n",
      "max        1.000000e+00            1.000000               1.000000   \n",
      "\n",
      "       signal_post_acquisition_layoff  ...  signal_department_specific  \\\n",
      "count                   199500.000000  ...               199500.000000   \n",
      "mean                         0.002961  ...                    0.005300   \n",
      "std                          0.027581  ...                    0.039579   \n",
      "min                          0.000000  ...                    0.000000   \n",
      "25%                          0.000000  ...                    0.000000   \n",
      "50%                          0.000000  ...                    0.000000   \n",
      "75%                          0.000000  ...                    0.000000   \n",
      "max                          1.000000  ...                    1.000000   \n",
      "\n",
      "       signal_senior_role_impact  signal_junior_role_impact  \\\n",
      "count              199500.000000              199500.000000   \n",
      "mean                    0.001069                   0.000454   \n",
      "std                     0.021683                   0.016416   \n",
      "min                     0.000000                   0.000000   \n",
      "25%                     0.000000                   0.000000   \n",
      "50%                     0.000000                   0.000000   \n",
      "75%                     0.000000                   0.000000   \n",
      "max                     1.000000                   1.000000   \n",
      "\n",
      "       signal_revenue_decline  signal_profitability_pressure  \\\n",
      "count           199500.000000                  199500.000000   \n",
      "mean                 0.007940                       0.014056   \n",
      "std                  0.043846                       0.051843   \n",
      "min                  0.000000                       0.000000   \n",
      "25%                  0.000000                       0.000000   \n",
      "50%                  0.000000                       0.000000   \n",
      "75%                  0.000000                       0.000000   \n",
      "max                  1.000000                       1.000000   \n",
      "\n",
      "       signal_runway_issue  signal_macroeconomic  signal_industry_downturn  \\\n",
      "count        199500.000000         199500.000000             199500.000000   \n",
      "mean              0.009543              0.038219                  0.014062   \n",
      "std               0.042227              0.080441                  0.051949   \n",
      "min               0.000000              0.000000                  0.000000   \n",
      "25%               0.000000              0.000000                  0.000000   \n",
      "50%               0.000000              0.000000                  0.000000   \n",
      "75%               0.000000              0.033133                  0.000000   \n",
      "max               1.000000              1.000000                  1.000000   \n",
      "\n",
      "       signal_geopolitical  signal_regulatory_pressure  \n",
      "count        199500.000000               199500.000000  \n",
      "mean              0.002258                    0.004765  \n",
      "std               0.027724                    0.036339  \n",
      "min               0.000000                    0.000000  \n",
      "25%               0.000000                    0.000000  \n",
      "50%               0.000000                    0.000000  \n",
      "75%               0.000000                    0.000000  \n",
      "max               1.000000                    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "HALF_LIFE = {\n",
    "    # ... your dictionary here ...\n",
    "    'forward_looking_flag': 3,\n",
    "    'backward_looking_flag': 1,\n",
    "    'timing_unclear_flag': 2,\n",
    "    'imminent_layoff_flag': 1,\n",
    "    'long_horizon_flag': 6,\n",
    "    'uncertainty_flag': 2,\n",
    "    'confirmed_flag': 1,\n",
    "    'acquisition_flag': 6,\n",
    "    'private_equity_flag': 6,\n",
    "    'post_acquisition_layoff_flag': 3,\n",
    "    'restructuring_flag': 4,\n",
    "    'cost_cutting_flag': 3,\n",
    "    'strategy_shift_flag': 4,\n",
    "    'automation_ai_flag': 4,\n",
    "    'product_exit_flag': 4,\n",
    "    'market_exit_flag': 4,\n",
    "    'offshoring_flag': 3,\n",
    "    'management_change_flag': 3,\n",
    "    'employee_unrest_flag': 1,\n",
    "    'attrition_flag': 2,\n",
    "    'repeat_layoff_flag': 6,\n",
    "    'department_specific_flag': 2,\n",
    "    'senior_role_impact_flag': 2,\n",
    "    'junior_role_impact_flag': 2,\n",
    "    'revenue_decline_flag': 6,\n",
    "    'profitability_pressure_flag': 6,\n",
    "    'runway_issue_flag': 6,\n",
    "    'macroeconomic_flag': 9,\n",
    "    'industry_downturn_flag': 9,\n",
    "    'geopolitical_flag': 9,\n",
    "    'regulatory_pressure_flag': 9\n",
    "}\n",
    "\n",
    "# --- 2. PREPROCESSING ---\n",
    "# Ensure data is sorted by company and date\n",
    "base_df = base_df.sort_values(['company', 'date']).reset_index(drop=True)\n",
    "\n",
    "# CRITICAL FIX: Fill NaNs with 0 to prevent NaN propagation\n",
    "event_flag_cols = list(HALF_LIFE.keys())\n",
    "base_df[event_flag_cols] = base_df[event_flag_cols].fillna(0)\n",
    "\n",
    "# Identify where new companies start (to reset the decay)\n",
    "# This creates a mask where True = start of a new company\n",
    "base_df['company_id'] = base_df['company'].astype('category').cat.codes\n",
    "company_change_mask = base_df['company_id'].diff() != 0\n",
    "company_change_indices = np.where(company_change_mask)[0]\n",
    "\n",
    "# --- 3. OPTIMIZED NUMPY FUNCTION ---\n",
    "def calculate_decay_numpy(values, alpha, reset_indices):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of decay using a linear scan in NumPy.\n",
    "    values: 1D numpy array of the flag column\n",
    "    alpha: float, decay factor\n",
    "    reset_indices: indices where a new company starts (reset signal to 0)\n",
    "    \"\"\"\n",
    "    n = len(values)\n",
    "    signal = np.zeros(n, dtype=np.float64)\n",
    "    \n",
    "    # We loop once through the array (O(N)), much faster than dataframe access\n",
    "    # We use a simple variable to track the running 'prev' value\n",
    "    current_val = 0.0\n",
    "    \n",
    "    # Iterate through the numpy array directly\n",
    "    for i in range(n):\n",
    "        # If we hit a new company index, reset the accumulator\n",
    "        if i in reset_indices:  # Note: checking set membership is faster, see optimization below\n",
    "            current_val = 0.0\n",
    "            \n",
    "        # Signal_t = Flag_t + alpha * Signal_t-1\n",
    "        current_val = values[i] + (alpha * current_val)\n",
    "        signal[i] = current_val\n",
    "        \n",
    "    return signal\n",
    "\n",
    "# Optimized runner\n",
    "signal_cols = []\n",
    "reset_indices_set = set(company_change_indices) # Set is O(1) lookup\n",
    "\n",
    "for flag in tqdm(event_flag_cols):\n",
    "    if flag not in base_df.columns:\n",
    "        continue\n",
    "        \n",
    "    signal_name = f'signal_{flag.replace(\"_flag\", \"\")}'\n",
    "    \n",
    "    # Calculate Alpha\n",
    "    alpha = 0.5 ** (1 / HALF_LIFE[flag])\n",
    "    \n",
    "    # Pass numpy array to function\n",
    "    values = base_df[flag].values\n",
    "    \n",
    "    # Compute\n",
    "    base_df[signal_name] = calculate_decay_numpy(values, alpha, reset_indices_set)\n",
    "    signal_cols.append(signal_name)\n",
    "\n",
    "# --- 4. SCALING ---\n",
    "# Only scale if max > 0 (avoid divide by zero)\n",
    "if signal_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    base_df[signal_cols] = scaler.fit_transform(base_df[signal_cols])\n",
    "\n",
    "# Verify results\n",
    "print(\"NaN Count:\", base_df[signal_cols].isna().sum().sum())\n",
    "print(base_df[signal_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c458a80-63f9-44fd-a3e4-b57654a5341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/synth_env/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def calculate_material_risk_and_binary(df, \n",
    "                                       w1=0.4, w2=0.4, w3=0.2, \n",
    "                                       lambda_vc=0.3,\n",
    "                                       materiality_threshold=0.1):\n",
    "    \"\"\"\n",
    "    1. Calculates 'material_risk_score' (0.0 - 1.0) using your Economic Severity formula.\n",
    "    2. Creates 'material_layoff_event' (0 or 1) by thresholding that score.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- PRE-COMPUTE CONSTANTS ---\n",
    "    # Global Max Funds (for normalization)\n",
    "    F_max = df['funds_raised'].max()\n",
    "    if pd.isna(F_max) or F_max == 0: F_max = 1 \n",
    "\n",
    "    # Handle missing values for calculation safety\n",
    "    # If final_count is NaN, it means 0 (no layoff)\n",
    "    final_count = df['final_count'].fillna(0)\n",
    "    final_pct = df['final_percentage'].fillna(0)\n",
    "    workforce = df[['total_workforce_est', 'final_count']].max(axis=1).fillna(1)\n",
    "    funds = df['funds_raised'].fillna(0)\n",
    "    is_vc = df['is_vc_backed'].fillna(0).astype(int)\n",
    "\n",
    "    # --- COMPONENT A: Absolute Scale Impact ---\n",
    "    # A = log(1 + C) / log(1 + W)\n",
    "    # Interpretation: Magnitude of cut relative to company size\n",
    "    comp_A = np.log1p(final_count) / np.log1p(workforce)\n",
    "\n",
    "    # --- COMPONENT B: Relative Workforce Impact ---\n",
    "    # R = P / 100\n",
    "    # Interpretation: % of company let go\n",
    "    comp_R = final_pct / 100.0\n",
    "\n",
    "    # --- COMPONENT C: Financial Fragility ---\n",
    "    # F_risk = 1 - (log(1 + F) / log(1 + F_max))\n",
    "    # Interpretation: Inverts funding (High funds -> Low risk)\n",
    "    comp_F_risk = 1 - (np.log1p(funds) / np.log1p(F_max))\n",
    "\n",
    "    # --- MODIFIER: Capital Buffer ---\n",
    "    # B = 1 - lambda * V\n",
    "    # Interpretation: VC backed companies get a risk reduction\n",
    "    modifier_B = 1 - (lambda_vc * is_vc)\n",
    "\n",
    "    # --- FINAL FORMULA ---\n",
    "    # MaterialRisk = B * (w1*A + w2*R + w3*F_risk)\n",
    "    raw_score = modifier_B * ((w1 * comp_A) + (w2 * comp_R) + (w3 * comp_F_risk))\n",
    "    \n",
    "    # MASKING: If no layoff happened (count=0), Severity is 0.\n",
    "    # (The formula might yield non-zero F_risk even if count is 0, so we must mask)\n",
    "    is_event = final_count > 0\n",
    "    df['material_risk_score'] = np.where(is_event, raw_score, 0.0)\n",
    "    \n",
    "    # Clip to valid range [0, 1]\n",
    "    df['material_risk_score'] = df['material_risk_score'].clip(0, 1)\n",
    "\n",
    "    # --- BINARY RESULT ---\n",
    "    # Convert the continuous score to the binary flag you requested.\n",
    "    # A layoff is \"Material\" if the calculated score exceeds the threshold.\n",
    "    # threshold=0.0 means ANY layoff is considered material (if that's what you want)\n",
    "    # threshold=0.1 filters out very minor \"noise\" layoffs in well-funded companies.\n",
    "    df['material_layoff_event'] = (df['material_risk_score'] > materiality_threshold).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- APPLY ---\n",
    "# You can adjust 'materiality_threshold' to control sensitivity.\n",
    "# 0.05 is a good baseline (keeps most layoffs, drops tiny ones in giants).\n",
    "base_df = calculate_material_risk_and_binary(base_df, materiality_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37c04cab-f191-4396-aa0d-5ae970d363c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Material Events:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>final_count</th>\n",
       "      <th>final_percentage</th>\n",
       "      <th>funds_raised</th>\n",
       "      <th>material_risk_score</th>\n",
       "      <th>material_layoff_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>#Paid</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>3.044523</td>\n",
       "      <td>0.343531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>&amp;Open</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0.336757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>100 Thieves</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>0.184511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>100 Thieves</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>0.189918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10X Genomics</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.312062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          company       date  final_count  final_percentage  funds_raised  \\\n",
       "34          #Paid 2023-01-01         19.0             0.170      3.044523   \n",
       "102         &Open 2022-11-01          9.0             0.090      3.555348   \n",
       "168   100 Thieves 2022-07-01         13.5             0.000      4.787492   \n",
       "174   100 Thieves 2023-01-01         15.0             0.075      4.787492   \n",
       "239  10X Genomics 2022-08-01        100.0             0.080      5.488938   \n",
       "\n",
       "     material_risk_score  material_layoff_event  \n",
       "34              0.343531                      1  \n",
       "102             0.336757                      1  \n",
       "168             0.184511                      1  \n",
       "174             0.189918                      1  \n",
       "239             0.312062                      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CHECK RESULTS ---\n",
    "cols = ['company', 'date', 'final_count', 'final_percentage', 'funds_raised', 'material_risk_score', 'material_layoff_event']\n",
    "# Show examples of Material Layoffs (1)\n",
    "print(\"Material Events:\")\n",
    "base_df[base_df['material_layoff_event'] == 1][cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351f7afd-a4ba-4391-b2e9-bd52fdaa9845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minor (Non-Material) Layoffs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>final_count</th>\n",
       "      <th>final_percentage</th>\n",
       "      <th>funds_raised</th>\n",
       "      <th>material_risk_score</th>\n",
       "      <th>material_layoff_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>123Milhas</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1K Kirana</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>888</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>Aakash</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        company       date  final_count  final_percentage  funds_raised  \\\n",
       "321   123Milhas 2023-08-01         42.0              0.00    -11.512925   \n",
       "387   1K Kirana 2023-04-01        400.0              0.40    -11.512925   \n",
       "1166        888 2024-01-01        100.0              0.00    -11.512925   \n",
       "1806        AMD 2024-11-01       1000.0              0.04    -11.512925   \n",
       "2014     Aakash 2024-09-01         90.0              0.00    -11.512925   \n",
       "\n",
       "      material_risk_score  material_layoff_event  \n",
       "321                   NaN                      0  \n",
       "387                   NaN                      0  \n",
       "1166                  NaN                      0  \n",
       "1806                  NaN                      0  \n",
       "2014                  NaN                      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show examples of layoffs that were NOT material (0) - if any exist\n",
    "print(\"\\nMinor (Non-Material) Layoffs:\")\n",
    "base_df[(base_df['final_count'] > 0) & (base_df['material_layoff_event'] == 0)][cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a9640e4-5bc5-4ade-81be-4c4c1801ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "material_layoff_event\n",
       "0    196572\n",
       "1      2928\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.material_layoff_event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cce8272-2466-4a37-824e-8c8f9ded0d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Company History...\n",
      "Generating Contextual Pressure...\n",
      "Generating Momentum...\n",
      "Features Generated.\n",
      "       company       date  layoff_count_6m  industry_pressure_index_3m  \\\n",
      "199495     xAI 2025-08-01              0.0                    0.086957   \n",
      "199496     xAI 2025-09-01              1.0                    0.173913   \n",
      "199497     xAI 2025-10-01              1.0                    0.130435   \n",
      "199498     xAI 2025-11-01              1.0                    0.086957   \n",
      "199499     xAI 2025-12-01              1.0                    0.000000   \n",
      "\n",
      "        macro_signal_delta_3m  \n",
      "199495                    0.0  \n",
      "199496                    0.0  \n",
      "199497                    0.0  \n",
      "199498                    0.0  \n",
      "199499                    0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Generates Company-Level History, Industry/Geo Context, and Momentum features.\n",
    "    Assumes df has: 'company', 'date', 'industry', 'country', \n",
    "                    'material_layoff_event' (0/1), 'material_risk_score' (0.0-1.0)\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['company', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. COMPANY-LEVEL ROLLING HISTORY\n",
    "    # ==========================================\n",
    "    print(\"Generating Company History...\")\n",
    "    \n",
    "    # A. Layoff Counts (Frequency)\n",
    "    # We use a loop for different windows to keep code clean\n",
    "    # closed='left' isn't strictly needed if we are careful about target shifting later,\n",
    "    # but strictly speaking, features at Time T include events at Time T.\n",
    "    for window in [3, 6, 12]:\n",
    "        col_name = f'layoff_count_{window}m'\n",
    "        # Group by company, rolling sum of the binary event\n",
    "        df[col_name] = df.groupby('company')['material_layoff_event'] \\\n",
    "                         .transform(lambda x: x.rolling(window, min_periods=1).sum()) \\\n",
    "                         .fillna(0)\n",
    "\n",
    "    # B. Severity History (Intensity)\n",
    "    # Track the MAXIMUM severity (risk score) seen in recent windows\n",
    "    for window in [6, 12]:\n",
    "        col_name = f'max_severity_{window}m'\n",
    "        df[col_name] = df.groupby('company')['material_risk_score'] \\\n",
    "                         .transform(lambda x: x.rolling(window, min_periods=1).max()) \\\n",
    "                         .fillna(0)\n",
    "\n",
    "    # C. Months Since Last Event (Recency) - (Optimized from previous step)\n",
    "    # If we already have it, skip. If not, recalculate.\n",
    "    if 'months_since_last_layoff' not in df.columns:\n",
    "        # Vectorized approach using cumsum groups\n",
    "        df['event_group'] = df.groupby('company')['material_layoff_event'].cumsum()\n",
    "        # Calculate months by grouping on the event_group (this is an approx heuristic)\n",
    "        # For exactness, we iterate. Let's stick to the reliable transform method:\n",
    "        def get_months_since(x):\n",
    "            last_idx = -999\n",
    "            res = []\n",
    "            for i, val in enumerate(x):\n",
    "                if val == 1: last_idx = i\n",
    "                res.append(i - last_idx)\n",
    "            return res\n",
    "        df['months_since_last_layoff'] = df.groupby('company')['material_layoff_event'].transform(get_months_since)\n",
    "        df['months_since_last_layoff'] = df['months_since_last_layoff'].clip(upper=24) # Cap at 24\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. CONTEXTUAL PRESSURE (Industry & Geo)\n",
    "    # ==========================================\n",
    "    print(\"Generating Contextual Pressure...\")\n",
    "    \n",
    "    # Helper to calculate group-level stats safely\n",
    "    def calculate_group_pressure(df, group_col, time_col='date'):\n",
    "        # 1. Aggregate to Group-Date level\n",
    "        # We count TOTAL material events and TOTAL active companies\n",
    "        group_stats = df.groupby([group_col, time_col]).agg(\n",
    "            total_events=('material_layoff_event', 'sum'),\n",
    "            active_companies=('company', 'count')\n",
    "        ).reset_index()\n",
    "        \n",
    "        # 2. Sort by date\n",
    "        group_stats = group_stats.sort_values([group_col, time_col])\n",
    "        \n",
    "        # 3. Calculate Rolling Sums on the GROUP level\n",
    "        # This tells us: \"How many layoffs in this industry in last 3 months?\"\n",
    "        for w in [3, 6]:\n",
    "            # Raw Count\n",
    "            group_stats[f'{group_col}_layoff_count_{w}m'] = group_stats.groupby(group_col)['total_events'] \\\n",
    "                .transform(lambda x: x.rolling(w, min_periods=1).sum())\n",
    "            \n",
    "            # Rate (Normalized by size of industry) - BETTER FEATURE\n",
    "            # We take the mean active companies over the window to normalize\n",
    "            avg_companies = group_stats.groupby(group_col)['active_companies'] \\\n",
    "                .transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
    "            \n",
    "            group_stats[f'{group_col}_pressure_index_{w}m'] = \\\n",
    "                group_stats[f'{group_col}_layoff_count_{w}m'] / avg_companies.replace(0, 1)\n",
    "\n",
    "        return group_stats\n",
    "\n",
    "    # A. Industry Pressure\n",
    "    industry_stats = calculate_group_pressure(df, 'industry')\n",
    "    # Merge back to main DF\n",
    "    df = df.merge(industry_stats[['industry', 'date', \n",
    "                                  'industry_layoff_count_3m', 'industry_pressure_index_3m',\n",
    "                                  'industry_layoff_count_6m', 'industry_pressure_index_6m']], \n",
    "                  on=['industry', 'date'], how='left')\n",
    "\n",
    "    # B. Geo Pressure\n",
    "    geo_stats = calculate_group_pressure(df, 'country')\n",
    "    df = df.merge(geo_stats[['country', 'date', \n",
    "                             'country_layoff_count_3m', 'country_pressure_index_3m',\n",
    "                             'country_layoff_count_6m', 'country_pressure_index_6m']], \n",
    "                  on=['country', 'date'], how='left')\n",
    "\n",
    "    # Fill NaNs from merge (if a company has no industry/country)\n",
    "    new_context_cols = [c for c in df.columns if 'industry_' in c or 'country_' in c]\n",
    "    df[new_context_cols] = df[new_context_cols].fillna(0)\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. MOMENTUM / DELTA (Advanced)\n",
    "    # ==========================================\n",
    "    print(\"Generating Momentum...\")\n",
    "    \n",
    "    # Calculate how much the \"Macro\" signal has changed in 3 months\n",
    "    # Positive = Risk is increasing\n",
    "    df['macro_signal_delta_3m'] = df.groupby('company')['signal_macroeconomic'].diff(3).fillna(0)\n",
    "    \n",
    "    # Industry Pressure Delta (Is the industry crashing NOW vs 3 months ago?)\n",
    "    # We take the 3m count and subtract the count from 3 months prior\n",
    "    df['industry_pressure_delta'] = df.groupby('company')['industry_layoff_count_3m'].diff(3).fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Apply to your processed_df\n",
    "# Ensure you have 'material_layoff_event' and 'material_risk_score' computed before running this!\n",
    "advanced_df = generate_advanced_features(base_df)\n",
    "\n",
    "# --- CHECK ---\n",
    "print(\"Features Generated.\")\n",
    "print(advanced_df[['company', 'date', 'layoff_count_6m', 'industry_pressure_index_3m', 'macro_signal_delta_3m']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02fb0d60-dc22-4a2a-bf49-e484cceaf9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'date', 'industry', 'stage', 'country', 'is_vc_backed',\n",
       "       'is_profitable', 'is_ai_pivot', 'business_model', 'total_workforce_est',\n",
       "       'funds_raised', 'forward_looking_flag', 'backward_looking_flag',\n",
       "       'timing_unclear_flag', 'imminent_layoff_flag', 'long_horizon_flag',\n",
       "       'uncertainty_flag', 'confirmed_flag', 'acquisition_flag',\n",
       "       'private_equity_flag', 'post_acquisition_layoff_flag',\n",
       "       'restructuring_flag', 'cost_cutting_flag', 'strategy_shift_flag',\n",
       "       'automation_ai_flag', 'product_exit_flag', 'market_exit_flag',\n",
       "       'offshoring_flag', 'management_change_flag', 'employee_unrest_flag',\n",
       "       'attrition_flag', 'repeat_layoff_flag', 'department_specific_flag',\n",
       "       'senior_role_impact_flag', 'junior_role_impact_flag',\n",
       "       'revenue_decline_flag', 'profitability_pressure_flag',\n",
       "       'runway_issue_flag', 'macroeconomic_flag', 'industry_downturn_flag',\n",
       "       'geopolitical_flag', 'regulatory_pressure_flag', 'final_count',\n",
       "       'final_percentage', 'event_type', 'quater', 'reason_category',\n",
       "       'company_id', 'signal_forward_looking', 'signal_backward_looking',\n",
       "       'signal_timing_unclear', 'signal_imminent_layoff',\n",
       "       'signal_long_horizon', 'signal_uncertainty', 'signal_confirmed',\n",
       "       'signal_acquisition', 'signal_private_equity',\n",
       "       'signal_post_acquisition_layoff', 'signal_restructuring',\n",
       "       'signal_cost_cutting', 'signal_strategy_shift', 'signal_automation_ai',\n",
       "       'signal_product_exit', 'signal_market_exit', 'signal_offshoring',\n",
       "       'signal_management_change', 'signal_employee_unrest',\n",
       "       'signal_attrition', 'signal_repeat_layoff',\n",
       "       'signal_department_specific', 'signal_senior_role_impact',\n",
       "       'signal_junior_role_impact', 'signal_revenue_decline',\n",
       "       'signal_profitability_pressure', 'signal_runway_issue',\n",
       "       'signal_macroeconomic', 'signal_industry_downturn',\n",
       "       'signal_geopolitical', 'signal_regulatory_pressure',\n",
       "       'material_risk_score', 'material_layoff_event', 'layoff_count_3m',\n",
       "       'layoff_count_6m', 'layoff_count_12m', 'max_severity_6m',\n",
       "       'max_severity_12m', 'event_group', 'months_since_last_layoff',\n",
       "       'industry_layoff_count_3m', 'industry_pressure_index_3m',\n",
       "       'industry_layoff_count_6m', 'industry_pressure_index_6m',\n",
       "       'country_layoff_count_3m', 'country_pressure_index_3m',\n",
       "       'country_layoff_count_6m', 'country_pressure_index_6m',\n",
       "       'macro_signal_delta_3m', 'industry_pressure_delta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e104bae0-bab3-4116-b74b-61683c42adad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 42 features...\n",
      "\n",
      "Final Dataset Shape: (196650, 99)\n",
      "Target Distribution (Next Month Layoffs):\n",
      "target\n",
      "0    193812\n",
      "1      2838\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 3 rows of features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_forward_looking</th>\n",
       "      <th>signal_backward_looking</th>\n",
       "      <th>signal_timing_unclear</th>\n",
       "      <th>signal_imminent_layoff</th>\n",
       "      <th>signal_long_horizon</th>\n",
       "      <th>signal_uncertainty</th>\n",
       "      <th>signal_confirmed</th>\n",
       "      <th>signal_acquisition</th>\n",
       "      <th>signal_private_equity</th>\n",
       "      <th>signal_post_acquisition_layoff</th>\n",
       "      <th>...</th>\n",
       "      <th>total_workforce_est</th>\n",
       "      <th>is_vc_backed</th>\n",
       "      <th>is_profitable</th>\n",
       "      <th>is_ai_pivot</th>\n",
       "      <th>layoff_count_6m</th>\n",
       "      <th>months_since_last_layoff</th>\n",
       "      <th>max_severity_12m</th>\n",
       "      <th>industry_pressure_index_3m</th>\n",
       "      <th>country_pressure_index_3m</th>\n",
       "      <th>macro_signal_delta_3m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118095</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.19522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438639</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.19522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522993</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.19522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_forward_looking  signal_backward_looking  signal_timing_unclear  \\\n",
       "0                     0.0                      0.0                    0.0   \n",
       "1                     0.0                      0.0                    0.0   \n",
       "2                     0.0                      0.0                    0.0   \n",
       "\n",
       "   signal_imminent_layoff  signal_long_horizon  signal_uncertainty  \\\n",
       "0                     0.0                  0.0                 0.0   \n",
       "1                     0.0                  0.0                 0.0   \n",
       "2                     0.0                  0.0                 0.0   \n",
       "\n",
       "   signal_confirmed  signal_acquisition  signal_private_equity  \\\n",
       "0               0.0                 0.0                    0.0   \n",
       "1               0.0                 0.0                    0.0   \n",
       "2               0.0                 0.0                    0.0   \n",
       "\n",
       "   signal_post_acquisition_layoff  ...  total_workforce_est  is_vc_backed  \\\n",
       "0                             0.0  ...                  0.0           1.0   \n",
       "1                             0.0  ...                  0.0           1.0   \n",
       "2                             0.0  ...                  0.0           1.0   \n",
       "\n",
       "   is_profitable  is_ai_pivot  layoff_count_6m  months_since_last_layoff  \\\n",
       "0            0.0          0.0              0.0                       1.0   \n",
       "1            0.0          0.0              0.0                       1.0   \n",
       "2            0.0          0.0              0.0                       1.0   \n",
       "\n",
       "   max_severity_12m  industry_pressure_index_3m  country_pressure_index_3m  \\\n",
       "0               0.0                    0.118095                   0.025424   \n",
       "1               0.0                    0.438639                   0.127119   \n",
       "2               0.0                    0.522993                   0.152542   \n",
       "\n",
       "   macro_signal_delta_3m  \n",
       "0                0.19522  \n",
       "1                0.19522  \n",
       "2                0.19522  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# 1. DEFINE YOUR FEATURE LIST\n",
    "feature_cols = [\n",
    "    # --- A. DECAYED SIGNALS (Narrative) ---\n",
    "    'signal_forward_looking', 'signal_backward_looking', 'signal_timing_unclear',\n",
    "    'signal_imminent_layoff', 'signal_long_horizon', 'signal_uncertainty',\n",
    "    'signal_confirmed', 'signal_acquisition', 'signal_private_equity',\n",
    "    'signal_post_acquisition_layoff', 'signal_restructuring', 'signal_cost_cutting',\n",
    "    'signal_strategy_shift', 'signal_automation_ai', 'signal_product_exit',\n",
    "    'signal_market_exit', 'signal_offshoring', 'signal_management_change',\n",
    "    'signal_employee_unrest', 'signal_attrition', 'signal_repeat_layoff',\n",
    "    'signal_department_specific', 'signal_senior_role_impact',\n",
    "    'signal_junior_role_impact', 'signal_revenue_decline',\n",
    "    'signal_profitability_pressure', 'signal_runway_issue',\n",
    "    'signal_macroeconomic', 'signal_industry_downturn', 'signal_geopolitical',\n",
    "    'signal_regulatory_pressure',\n",
    "\n",
    "    # --- B. COMPANY STATE (Financials) ---\n",
    "    'funds_raised', 'total_workforce_est', \n",
    "    'is_vc_backed', 'is_profitable', 'is_ai_pivot',\n",
    "\n",
    "    # --- C. HISTORY (The \"Memory\" of past pain) ---\n",
    "    'layoff_count_6m',          # Frequency\n",
    "    'months_since_last_layoff', # Recency\n",
    "    'max_severity_12m',         # Intensity\n",
    "\n",
    "    # --- D. CONTEXT (The \"Contagion\") ---\n",
    "    'industry_pressure_index_3m', # Sector stress\n",
    "    'country_pressure_index_3m',  # Regional stress\n",
    "    \n",
    "    # --- E. MOMENTUM (The \"Speed\" of change) ---\n",
    "    'macro_signal_delta_3m'\n",
    "]\n",
    "\n",
    "def finalize_dataset(df, features):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Target Creation (Shift -1 to predict Next Month)\n",
    "    # We must do this BEFORE any dropping/sorting\n",
    "    df = df.sort_values(['company', 'date'])\n",
    "    df['target'] = df.groupby('company')['material_layoff_event'].shift(-1)\n",
    "    \n",
    "    # Drop rows where target is NaN (the last month of data for every company)\n",
    "    df = df.dropna(subset=['target'])\n",
    "    df['target'] = df['target'].astype(int)\n",
    "\n",
    "    # 2. Handling Booleans\n",
    "    # Convert bool columns to 0/1 integers\n",
    "    bool_cols = ['is_vc_backed', 'is_profitable', 'is_ai_pivot']\n",
    "    for c in bool_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(0).astype(int)\n",
    "\n",
    "    # 3. Filling NaNs\n",
    "    # Signals/Counts -> 0\n",
    "    # Context -> 0 (assume average/no pressure if unknown)\n",
    "    # Financials -> Median or 0? Let's use 0 for robust LSTM handling (it learns 0 = missing)\n",
    "    df[features] = df[features].fillna(0)\n",
    "\n",
    "    # 4. Scaling (CRITICAL FOR LSTM)\n",
    "    # We fit the scaler on the features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "    return df, scaler\n",
    "\n",
    "# --- EXECUTE ---\n",
    "print(f\"Selecting {len(feature_cols)} features...\")\n",
    "final_df, feature_scaler = finalize_dataset(advanced_df, feature_cols)\n",
    "\n",
    "# --- VALIDATION ---\n",
    "print(f\"\\nFinal Dataset Shape: {final_df.shape}\")\n",
    "print(f\"Target Distribution (Next Month Layoffs):\\n{final_df['target'].value_counts()}\")\n",
    "print(\"\\nFirst 3 rows of features:\")\n",
    "final_df[feature_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "575c105d-5798-494e-960e-551ec2cd9798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-03-01 00:00:00'), Timestamp('2025-12-01 00:00:00'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.min(), df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d805850c-e819-4e87-b6b7-480dc6c79b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Walk-Forward Step 1: Predict Jan 2025\n",
      "Generating TRAIN sequences (Target < 2024-12-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2759.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2254.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DATA SHAPES ---\n",
      "X_train: (128250, 12, 42)\n",
      "y_train: (128250,)\n",
      "X_test:  (2850, 12, 42)\n",
      "y_test:  (2850,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. DEFINE THE SEQUENCE CREATOR FUNCTION ---\n",
    "def create_sequences(df, seq_length, features, target):\n",
    "    \"\"\"\n",
    "    Converts a flat dataframe into (Samples, TimeSteps, Features) tensors.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    companies = [] \n",
    "    dates = []     \n",
    "    \n",
    "    # Group by company to ensure we don't mix data between companies\n",
    "    # Using tqdm to show progress\n",
    "    for company_name, group in tqdm(df.groupby('company'), desc=\"Building Sequences\"):\n",
    "        # Convert group to values\n",
    "        data_values = group[features].values\n",
    "        target_values = group[target].values\n",
    "        date_values = group['date'].values\n",
    "        \n",
    "        # We need at least seq_length rows to make 1 sequence\n",
    "        if len(data_values) < seq_length:\n",
    "            continue\n",
    "            \n",
    "        # Sliding window\n",
    "        for i in range(len(data_values) - seq_length):\n",
    "            # Input: T to T+seq_len\n",
    "            X.append(data_values[i : i + seq_length])\n",
    "            \n",
    "            # Target: The target associated with the LAST step of the sequence\n",
    "            y.append(target_values[i + seq_length - 1])\n",
    "            \n",
    "            companies.append(company_name)\n",
    "            dates.append(date_values[i + seq_length - 1])\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(companies), np.array(dates)\n",
    "\n",
    "# --- 2. DEFINE THE SPLIT FUNCTION (NUMPY VERSION) ---\n",
    "def get_train_test_data_numpy(df, split_date, seq_len, features, target_col):\n",
    "    split_ts = pd.Timestamp(split_date)\n",
    "    \n",
    "    # Filter Dataframes\n",
    "    train_df = df[df['date'] < split_ts]\n",
    "    test_df_pool = df[df['date'] <= split_ts]\n",
    "    \n",
    "    # Generate Train Sequences\n",
    "    print(f\"Generating TRAIN sequences (Target < {split_date})...\")\n",
    "    X_train, y_train, _, _ = create_sequences(train_df, seq_len, features, target_col)\n",
    "    \n",
    "    # Generate Test Sequences (One per company ending on Split Date)\n",
    "    print(f\"Generating TEST sequences (Predicting Jan 2025)...\")\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    test_companies = []\n",
    "    \n",
    "    for company, group in tqdm(test_df_pool.groupby('company'), desc=\"Building Test Set\"):\n",
    "        group = group.sort_values('date')\n",
    "        \n",
    "        # We need the last row to be exactly the split_date\n",
    "        if group.empty or group.iloc[-1]['date'] != split_ts:\n",
    "            continue\n",
    "            \n",
    "        # Check if we have enough history\n",
    "        if len(group) < seq_len:\n",
    "            continue\n",
    "            \n",
    "        # Grab the last SEQ_LEN rows\n",
    "        seq = group.iloc[-seq_len:]\n",
    "        \n",
    "        X_test.append(seq[features].values)\n",
    "        y_test.append(seq.iloc[-1][target_col])\n",
    "        test_companies.append(company)\n",
    "\n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test), test_companies\n",
    "\n",
    "# --- 3. EXECUTE ---\n",
    "# Configuration\n",
    "SPLIT_DATE = '2024-12-01'\n",
    "SEQUENCE_LENGTH = 12\n",
    "\n",
    "print(f\"Preparing Walk-Forward Step 1: Predict Jan 2025\")\n",
    "X_train, y_train, X_test, y_test, test_companies = get_train_test_data_numpy(\n",
    "    final_df, \n",
    "    SPLIT_DATE, \n",
    "    SEQUENCE_LENGTH, \n",
    "    feature_cols, \n",
    "    'target'\n",
    ")\n",
    "\n",
    "print(\"\\n--- DATA SHAPES ---\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "print(f\"y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "527db0a6-ba18-4343-a682-c73b76131b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/synth_env/lib/python3.10/site-packages/google/api_core/_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.5087993525453853, 1: 28.911181244364293}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def build_lstm_model(input_shape, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1. Input Layer matching your (TimeSteps, Features)\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    # 2. Masking (Optional but good practice)\n",
    "    # Ignores timesteps where all features are 0 (padding)\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    \n",
    "    # 3. LSTM Layer\n",
    "    # units=64: Can be tuned (32, 64, 128)\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    \n",
    "    # 4. Dropout for Regularization\n",
    "    # Prevents overfitting on the training data\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # 5. Output Layer\n",
    "    # Sigmoid activation outputs a probability between 0.0 and 1.0\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # 6. Compile\n",
    "    # AUC is the best metric for your imbalanced data\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- CALCULATE CLASS WEIGHTS ---\n",
    "# Layoffs are rare (1.5%). If we don't weight them, the model learns to say \"0\" always.\n",
    "# We punish the model ~60x more for missing a layoff than for false alarm.\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(weights))\n",
    "print(f\"Class Weights: {class_weights}\")\n",
    "# Expected output: {0: 0.51, 1: ~33.0} (Exact numbers will vary based on your data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "971e5ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for Jan 2025 Prediction...\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 4s 28ms/step - loss: 0.6498 - auc: 0.6436 - recall: 0.6890 - val_loss: 0.6622 - val_auc: 0.7186 - val_recall: 0.8609\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5931 - auc: 0.7301 - recall: 0.7796 - val_loss: 0.6663 - val_auc: 0.7644 - val_recall: 0.8896\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5610 - auc: 0.7686 - recall: 0.7734 - val_loss: 0.6895 - val_auc: 0.7694 - val_recall: 0.8830\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 3s 25ms/step - loss: 0.5509 - auc: 0.7785 - recall: 0.7643 - val_loss: 0.5147 - val_auc: 0.7663 - val_recall: 0.6424\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5499 - auc: 0.7799 - recall: 0.7700 - val_loss: 0.5724 - val_auc: 0.7781 - val_recall: 0.7859\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5409 - auc: 0.7873 - recall: 0.7756 - val_loss: 0.4776 - val_auc: 0.7802 - val_recall: 0.6358\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5370 - auc: 0.7896 - recall: 0.7671 - val_loss: 0.4895 - val_auc: 0.7843 - val_recall: 0.7130\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5320 - auc: 0.7952 - recall: 0.7796 - val_loss: 0.4955 - val_auc: 0.7842 - val_recall: 0.6733\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 3s 25ms/step - loss: 0.5316 - auc: 0.7957 - recall: 0.7858 - val_loss: 0.5207 - val_auc: 0.7828 - val_recall: 0.7042\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5255 - auc: 0.8012 - recall: 0.7960 - val_loss: 0.4869 - val_auc: 0.7877 - val_recall: 0.6512\n",
      "Epoch 11/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.5241 - auc: 0.8020 - recall: 0.7876Restoring model weights from the end of the best epoch: 6.\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5237 - auc: 0.8019 - recall: 0.7887 - val_loss: 0.5676 - val_auc: 0.7900 - val_recall: 0.7815\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup Model\n",
    "# X_train shape is (Samples, 12, N_Features)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# 2. Setup Callbacks\n",
    "# Stop training if validation loss doesn't improve for 5 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. Train\n",
    "print(\"Starting Training for Jan 2025 Prediction...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,                  # Max epochs (will stop early likely)\n",
    "    batch_size=1024,            # Large batch size helps with noise\n",
    "    validation_split=0.2,       # Use 20% of history to validate model quality\n",
    "    class_weight=class_weights, # CRITICAL: Apply the imbalance fix\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3943ccf-626a-4580-bde6-a7c2edd52a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTS FOR JAN 2025 PREDICTION ---\n",
      "ROC-AUC Score: 0.7944 (Baseline: 0.5)\n",
      "PR-AUC Score:  0.0314 (Baseline: 0.0067)\n",
      "\n",
      "Top 5 Highest Predicted Risks:\n",
      "        company  actual_layoff  predicted_risk\n",
      "100      Amazon              0        0.903710\n",
      "1044     Google              0        0.855753\n",
      "2062     Rivian              0        0.842747\n",
      "1556  Microsoft              1        0.827940\n",
      "138       Apple              0        0.814330\n",
      "\n",
      "Successful Hits (Risk > 0.5 and Actual = 1):\n",
      "        company  actual_layoff  predicted_risk\n",
      "1556  Microsoft              1        0.827940\n",
      "2166  ShareChat              1        0.585790\n",
      "2252  SolarEdge              1        0.757909\n",
      "2329     Stripe              1        0.503449\n",
      "2424     Textio              1        0.582951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "# 1. Predict on the Test Set (Jan 2025)\n",
    "# These are probabilities (0.0 to 1.0)\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "\n",
    "# 2. Evaluation\n",
    "# ROC-AUC (Global Ranking Quality)\n",
    "roc_score = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "# PR-AUC (Precision-Recall Area Under Curve)\n",
    "# This is the \"Truth Teller\" for rare events.\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(\"\\n--- RESULTS FOR JAN 2025 PREDICTION ---\")\n",
    "print(f\"ROC-AUC Score: {roc_score:.4f} (Baseline: 0.5)\")\n",
    "print(f\"PR-AUC Score:  {pr_auc:.4f} (Baseline: {y_test.mean():.4f})\")\n",
    "\n",
    "# 3. Inspect the Riskiest Companies\n",
    "results_df = pd.DataFrame({\n",
    "    'company': test_companies,\n",
    "    'actual_layoff': y_test,\n",
    "    'predicted_risk': y_pred_probs.flatten()\n",
    "})\n",
    "\n",
    "# Show top 5 highest risk companies\n",
    "print(\"\\nTop 5 Highest Predicted Risks:\")\n",
    "print(results_df.sort_values('predicted_risk', ascending=False).head(5))\n",
    "\n",
    "# Show actual hits (Where we predicted high risk AND they fired)\n",
    "print(\"\\nSuccessful Hits (Risk > 0.5 and Actual = 1):\")\n",
    "print(results_df[(results_df['predicted_risk'] > 0.5) & (results_df['actual_layoff'] == 1)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d49c58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PROBABILITY METRICS (JAN 2025) ---\n",
      "ROC-AUC Score: 0.7944 (Baseline: 0.5)\n",
      "PR-AUC Score:  0.0314 (Baseline: 0.0067)\n",
      "\n",
      "--- CLASSIFICATION REPORT (Threshold = 0.3) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Layoff       1.00      0.69      0.82      2831\n",
      "      Layoff       0.02      0.79      0.03        19\n",
      "\n",
      "    accuracy                           0.69      2850\n",
      "   macro avg       0.51      0.74      0.43      2850\n",
      "weighted avg       0.99      0.69      0.81      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1965  866]\n",
      " [   4   15]]\n",
      "\n",
      "F1-Score (Positive Class): 0.0333\n",
      "\n",
      "Summary:\n",
      "- Correctly caught 15 layoffs.\n",
      "- Missed 4 layoffs.\n",
      "- Raised 866 false alarms.\n",
      "\n",
      "Top 5 Highest Predicted Risks:\n",
      "        company  actual_layoff  predicted_risk\n",
      "100      Amazon              0        0.903710\n",
      "1044     Google              0        0.855753\n",
      "2062     Rivian              0        0.842747\n",
      "1556  Microsoft              1        0.827940\n",
      "138       Apple              0        0.814330\n",
      "\n",
      "Successful Hits (Risk > 0.3 and Actual = 1):\n",
      "           company  actual_layoff  predicted_risk\n",
      "98        Altruist              1        0.325503\n",
      "135       AppLovin              1        0.457398\n",
      "191    Aurora Labs              1        0.367739\n",
      "192   Aurora Solar              1        0.305677\n",
      "1113       HeyJobs              1        0.318125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve, \n",
    "    auc, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    f1_score\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Predict on the Test Set (Jan 2025)\n",
    "# These are probabilities (0.0 to 1.0)\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "\n",
    "# ==========================================\n",
    "# PART A: PROBABILITY METRICS (Ranking Quality)\n",
    "# ==========================================\n",
    "# ROC-AUC (Global Ranking Quality)\n",
    "roc_score = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "# PR-AUC (Precision-Recall Area Under Curve)\n",
    "# This is the \"Truth Teller\" for rare events.\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "print(\"\\n--- PROBABILITY METRICS (JAN 2025) ---\")\n",
    "print(f\"ROC-AUC Score: {roc_score:.4f} (Baseline: 0.5)\")\n",
    "print(f\"PR-AUC Score:  {pr_auc:.4f} (Baseline: {y_test.mean():.4f})\")\n",
    "\n",
    "# ==========================================\n",
    "# PART B: CLASSIFICATION METRICS (Hard Decisions)\n",
    "# ==========================================\n",
    "# We use a threshold to convert probability -> 0 or 1.\n",
    "# Standard is 0.5, but for rare events like layoffs, you might experiment with lower (e.g., 0.3)\n",
    "THRESHOLD = 0.3\n",
    "y_pred_classes = (y_pred_probs > THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"\\n--- CLASSIFICATION REPORT (Threshold = {THRESHOLD}) ---\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=['No Layoff', 'Layoff']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "# [TN, FP]\n",
    "# [FN, TP]\n",
    "\n",
    "# Specific F1 Score for the Positive Class\n",
    "f1 = f1_score(y_test, y_pred_classes)\n",
    "print(f\"\\nF1-Score (Positive Class): {f1:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "tp = cm[1, 1] # True Positives (Caught)\n",
    "fn = cm[1, 0] # False Negatives (Missed)\n",
    "fp = cm[0, 1] # False Positives (False Alarm)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Correctly caught {tp} layoffs.\")\n",
    "print(f\"- Missed {fn} layoffs.\")\n",
    "print(f\"- Raised {fp} false alarms.\")\n",
    "\n",
    "# ==========================================\n",
    "# PART C: INSPECTION (Qualitative Check)\n",
    "# ==========================================\n",
    "# Inspect the Riskiest Companies\n",
    "results_df = pd.DataFrame({\n",
    "    'company': test_companies,\n",
    "    'actual_layoff': y_test,\n",
    "    'predicted_risk': y_pred_probs.flatten()\n",
    "})\n",
    "\n",
    "# Show top 5 highest risk companies\n",
    "print(\"\\nTop 5 Highest Predicted Risks:\")\n",
    "print(results_df.sort_values('predicted_risk', ascending=False).head(5))\n",
    "\n",
    "# Show actual hits (Where we predicted high risk AND they fired)\n",
    "print(f\"\\nSuccessful Hits (Risk > {THRESHOLD} and Actual = 1):\")\n",
    "print(results_df[(results_df['predicted_risk'] > THRESHOLD) & (results_df['actual_layoff'] == 1)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd8a29db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Walk-Forward Prediction for 12 months...\n",
      "\n",
      "============================================================\n",
      "ROUND 1/12: Training up to 2024-12-01 -> Predicting 2025-01-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2024-12-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2791.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2189.40it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 128250 | Class Weights: {0: 0.5087993525453853, 1: 28.911181244364293}\n",
      "\n",
      "--- REPORT FOR 2025-01-01 (Best Thresh: 0.722) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      0.99      0.99      2831\n",
      "      Layoff       0.10      0.11      0.10        19\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.54      0.55      0.55      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2812   19]\n",
      " [  17    2]]\n",
      "\n",
      "============================================================\n",
      "ROUND 2/12: Training up to 2025-01-01 -> Predicting 2025-02-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-01-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2643.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2246.67it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 131100 | Class Weights: {0: 0.508667918613133, 1: 29.34198746642793}\n",
      "\n",
      "--- REPORT FOR 2025-02-01 (Best Thresh: 0.664) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      1.00      0.99      2809\n",
      "      Layoff       0.50      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.74      0.54      0.56      2850\n",
      "weighted avg       0.98      0.99      0.98      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2806    3]\n",
      " [  38    3]]\n",
      "\n",
      "============================================================\n",
      "ROUND 3/12: Training up to 2025-02-01 -> Predicting 2025-03-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-02-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2557.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2207.61it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 133950 | Class Weights: {0: 0.508553725597394, 1: 29.727030625832224}\n",
      "\n",
      "--- REPORT FOR 2025-03-01 (Best Thresh: 0.595) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      0.97      0.98      2836\n",
      "      Layoff       0.06      0.36      0.11        14\n",
      "\n",
      "    accuracy                           0.97      2850\n",
      "   macro avg       0.53      0.67      0.55      2850\n",
      "weighted avg       0.99      0.97      0.98      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2760   76]\n",
      " [   9    5]]\n",
      "\n",
      "============================================================\n",
      "ROUND 4/12: Training up to 2025-03-01 -> Predicting 2025-04-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-03-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2187.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2085.84it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 136800 | Class Weights: {0: 0.5085275006319421, 1: 29.81691368788143}\n",
      "\n",
      "--- REPORT FOR 2025-04-01 (Best Thresh: 0.735) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      0.99      1.00      2835\n",
      "      Layoff       0.17      0.20      0.18        15\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.58      0.60      0.59      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2820   15]\n",
      " [  12    3]]\n",
      "\n",
      "============================================================\n",
      "ROUND 5/12: Training up to 2025-04-01 -> Predicting 2025-05-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-04-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2524.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2137.46it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 139650 | Class Weights: {0: 0.5084023823739279, 1: 30.253466204506065}\n",
      "\n",
      "--- REPORT FOR 2025-05-01 (Best Thresh: 0.735) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      0.99      0.99      2830\n",
      "      Layoff       0.20      0.20      0.20        20\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.60      0.60      0.60      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2814   16]\n",
      " [  16    4]]\n",
      "\n",
      "============================================================\n",
      "ROUND 6/12: Training up to 2025-05-01 -> Predicting 2025-06-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-05-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2427.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2098.19it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 142500 | Class Weights: {0: 0.5082859527597252, 1: 30.671545415411106}\n",
      "\n",
      "--- REPORT FOR 2025-06-01 (Best Thresh: 0.801) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      1.00      1.00      2838\n",
      "      Layoff       0.36      0.33      0.35        12\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.68      0.67      0.67      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2831    7]\n",
      " [   8    4]]\n",
      "\n",
      "============================================================\n",
      "ROUND 7/12: Training up to 2025-06-01 -> Predicting 2025-07-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-06-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2242.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 1990.18it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 145350 | Class Weights: {0: 0.5081919066898823, 1: 31.017925736235597}\n",
      "\n",
      "--- REPORT FOR 2025-07-01 (Best Thresh: 0.805) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      1.00      1.00      2833\n",
      "      Layoff       0.40      0.12      0.18        17\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.70      0.56      0.59      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2830    3]\n",
      " [  15    2]]\n",
      "\n",
      "============================================================\n",
      "ROUND 8/12: Training up to 2025-07-01 -> Predicting 2025-08-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-07-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2421.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2114.94it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 148200 | Class Weights: {0: 0.5080736398230998, 1: 31.46496815286624}\n",
      "\n",
      "--- REPORT FOR 2025-08-01 (Best Thresh: 0.726) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      0.99      1.00      2837\n",
      "      Layoff       0.06      0.08      0.07        13\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.53      0.54      0.53      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2822   15]\n",
      " [  12    1]]\n",
      "\n",
      "============================================================\n",
      "ROUND 9/12: Training up to 2025-08-01 -> Predicting 2025-09-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-08-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2341.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2091.79it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 151050 | Class Weights: {0: 0.5079769703654878, 1: 31.840219224283306}\n",
      "\n",
      "--- REPORT FOR 2025-09-01 (Best Thresh: 0.693) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      0.99      1.00      2833\n",
      "      Layoff       0.24      0.29      0.26        17\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.62      0.64      0.63      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2817   16]\n",
      " [  12    5]]\n",
      "\n",
      "============================================================\n",
      "ROUND 10/12: Training up to 2025-09-01 -> Predicting 2025-10-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-09-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2386.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 2401.51it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 153900 | Class Weights: {0: 0.5078705078705079, 1: 32.264150943396224}\n",
      "\n",
      "--- REPORT FOR 2025-10-01 (Best Thresh: 0.793) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      1.00      1.00      2831\n",
      "      Layoff       0.60      0.16      0.25        19\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.80      0.58      0.62      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2829    2]\n",
      " [  16    3]]\n",
      "\n",
      "============================================================\n",
      "ROUND 11/12: Training up to 2025-10-01 -> Predicting 2025-11-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-10-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2771.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:01<00:00, 1898.09it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 156750 | Class Weights: {0: 0.5077811179931064, 1: 32.629059117402164}\n",
      "\n",
      "--- REPORT FOR 2025-11-01 (Best Thresh: 0.786) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      1.00      1.00      2834\n",
      "      Layoff       0.08      0.06      0.07        16\n",
      "\n",
      "    accuracy                           0.99      2850\n",
      "   macro avg       0.54      0.53      0.53      2850\n",
      "weighted avg       0.99      0.99      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2823   11]\n",
      " [  15    1]]\n",
      "\n",
      "============================================================\n",
      "ROUND 12/12: Training up to 2025-11-01 -> Predicting 2025-12-01\n",
      "============================================================\n",
      "Generating TRAIN sequences (Target < 2025-11-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Sequences: 100%|██████████| 2850/2850 [00:01<00:00, 2268.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TEST sequences (Predicting Jan 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Test Set: 100%|██████████| 2850/2850 [00:00<00:00, 3831.13it/s]\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Training Samples: 159600 | Class Weights: {0: 0.5077014104937683, 1: 32.96158612143742}\n",
      "\n",
      "--- REPORT FOR 2025-12-01 (Best Thresh: 0.906) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      1.00      1.00      2836\n",
      "      Layoff       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           1.00      2850\n",
      "   macro avg       1.00      0.54      0.57      2850\n",
      "weighted avg       1.00      1.00      0.99      2850\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2836    0]\n",
      " [  13    1]]\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "PREDICTION_MONTHS = [\n",
    "    '2025-01-01', '2025-02-01', '2025-03-01', '2025-04-01',\n",
    "    '2025-05-01', '2025-06-01', '2025-07-01', '2025-08-01',\n",
    "    '2025-09-01', '2025-10-01', '2025-11-01', '2025-12-01'\n",
    "]\n",
    "SEQUENCE_LENGTH = 12\n",
    "results_list = []\n",
    "\n",
    "print(f\"Starting Walk-Forward Prediction for {len(PREDICTION_MONTHS)} months...\")\n",
    "\n",
    "for i, pred_date_str in enumerate(PREDICTION_MONTHS):\n",
    "    # 1. Define Dates\n",
    "    # We train on everything UP TO the month before prediction\n",
    "    pred_ts = pd.Timestamp(pred_date_str)\n",
    "    split_ts = pred_ts - pd.DateOffset(months=1)\n",
    "    split_date_str = split_ts.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ROUND {i+1}/{len(PREDICTION_MONTHS)}: Training up to {split_date_str} -> Predicting {pred_date_str}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 2. Get Data (Expanding Window)\n",
    "    # This function (from previous steps) splits data based on the date provided\n",
    "    X_train, y_train, X_test, y_test, test_companies = get_train_test_data_numpy(\n",
    "        final_df, split_date_str, SEQUENCE_LENGTH, feature_cols, 'target'\n",
    "    )\n",
    "    \n",
    "    # Safety Check\n",
    "    if len(X_test) == 0:\n",
    "        print(f\"No test data for {pred_date_str}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 3. Compute Class Weights DYNAMICALLY\n",
    "    # As the training set grows, the balance might change slightly\n",
    "    weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weights = dict(enumerate(weights))\n",
    "    print(f\"   > Training Samples: {len(y_train)} | Class Weights: {class_weights}\")\n",
    "    \n",
    "    # 4. Build & Train Model\n",
    "    # We rebuild fresh to avoid leakage from previous loop iterations\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,               # Enough for convergence with early stopping\n",
    "        batch_size=1024,\n",
    "        validation_split=0.1,    # Use last 10% of training data for validation\n",
    "        class_weight=class_weights, # <--- APPLYING YOUR WEIGHTS HERE\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0                # Silent training\n",
    "    )\n",
    "    \n",
    "    # 5. Predict\n",
    "    probs = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    # 6. Generate Monthly Report\n",
    "    # We find the 'best' threshold for this month just to illustrate performance potential\n",
    "    # (In production, you'd pick one fixed threshold, but for reporting we show the best F1)\n",
    "    \n",
    "    # Check if we have any layoffs to evaluate against\n",
    "    if sum(y_test) > 0:\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, probs)\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        current_threshold = thresholds[best_idx]\n",
    "        \n",
    "        # Apply Threshold\n",
    "        preds = (probs >= current_threshold).astype(int)\n",
    "        \n",
    "        # Print Report\n",
    "        print(f\"\\n--- REPORT FOR {pred_date_str} (Best Thresh: {current_threshold:.3f}) ---\")\n",
    "        print(classification_report(y_test, preds, target_names=['Safe', 'Layoff']))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, preds))\n",
    "        \n",
    "        # [TN, FP]\n",
    "        # [FN, TP]\n",
    "    else:\n",
    "        print(f\"\\n--- REPORT FOR {pred_date_str} ---\")\n",
    "        print(\"No actual layoffs occurred in this test month.\")\n",
    "        print(f\"Max predicted risk was: {probs.max():.4f}\")\n",
    "\n",
    "    # 7. Store Results\n",
    "    month_df = pd.DataFrame({\n",
    "        'prediction_date': pred_date_str,\n",
    "        'company': test_companies,\n",
    "        'predicted_risk': probs,\n",
    "        'actual_layoff': y_test\n",
    "    })\n",
    "    results_list.append(month_df)\n",
    "\n",
    "# --- END LOOP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d0def86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GLOBAL SUMMARY (JAN 2025 - DEC 2025)\n",
      "============================================================\n",
      "Total Companies Evaluated: 34200\n",
      "Total Actual Layoffs: 217\n",
      "Optimal Global Threshold: 0.7649\n",
      "Max F1 Score: 0.1212\n",
      "\n",
      "Global Confusion Matrix:\n",
      "[[33890    93]\n",
      " [  197    20]]\n",
      "\n",
      "Global Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       0.99      1.00      1.00     33983\n",
      "      Layoff       0.18      0.09      0.12       217\n",
      "\n",
      "    accuracy                           0.99     34200\n",
      "   macro avg       0.59      0.54      0.56     34200\n",
      "weighted avg       0.99      0.99      0.99     34200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all months\n",
    "all_predictions = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GLOBAL SUMMARY (JAN 2025 - DEC 2025)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Find Optimal Global Threshold\n",
    "y_true_all = all_predictions['actual_layoff']\n",
    "y_prob_all = all_predictions['predicted_risk']\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true_all, y_prob_all)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "best_global_idx = np.argmax(f1_scores)\n",
    "best_global_threshold = thresholds[best_global_idx]\n",
    "\n",
    "print(f\"Total Companies Evaluated: {len(all_predictions)}\")\n",
    "print(f\"Total Actual Layoffs: {y_true_all.sum()}\")\n",
    "print(f\"Optimal Global Threshold: {best_global_threshold:.4f}\")\n",
    "print(f\"Max F1 Score: {f1_scores[best_global_idx]:.4f}\")\n",
    "\n",
    "# Apply Threshold\n",
    "all_predictions['predicted_label'] = (all_predictions['predicted_risk'] >= best_global_threshold).astype(int)\n",
    "\n",
    "# Final Confusion Matrix\n",
    "cm = confusion_matrix(y_true_all, all_predictions['predicted_label'])\n",
    "print(\"\\nGlobal Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nGlobal Classification Report:\")\n",
    "print(classification_report(y_true_all, all_predictions['predicted_label'], target_names=['Safe', 'Layoff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762150a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
